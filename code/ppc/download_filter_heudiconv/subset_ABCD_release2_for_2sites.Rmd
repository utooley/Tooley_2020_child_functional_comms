---
title: "Filtering Out ABCD Participants From Release 2 for 2 Sites with 'Good' RS Data"
output: html_document
---
# Starting from scratch for participants with T1s in Release 2.0

Found out in mid-January that there are only ~2600 T1s in release 1.1, so need to filter on having a release ppc-ed T1 first. Here, I start from the .txt files instead of the compiled .RDS data on my local computer, and just try to pull a subject list that I can start downloading.

```{r Read in all text files, echo=FALSE}
library(dplyr)
library(summarytools)
#local computer
data_dir='~/Documents/projects/in_progress/spatial_topography_parcellations_ABCD/data/subjData/Release2/'
output_data_dir='~/Documents/projects/in_progress/spatial_topography_parcellations_ABCD/data/subjData/Release2/'
subjlist_dir='/Users/utooley/Documents/projects/in_progress/spatial_topography_parcellations_ABCD/data/subjLists/release2/'
procfmri <- read.delim(paste0(data_dir,"fmriresults01.txt"))
procfmri = procfmri[-1,]
procfmri = droplevels(procfmri)
procfmri <- select(procfmri, -c(collection_id:dataset_id))
procfmri$subjectid <- procfmri$subjectkey
mriqc1 <- read.delim(paste0(data_dir,"mriqcrp102.txt"))
mriqc1 = mriqc1[-1,]
mriqc1 = droplevels(mriqc1)
mriqc1 <- select(mriqc1, -c(collection_id:dataset_id))
mriqc1$subjectid <- mriqc1$subjectkey
mriqc2 <- read.delim(paste0(data_dir,"mriqcrp202.txt"))
mriqc2 = mriqc2[-1,]
mriqc2 = droplevels(mriqc2)
mriqc2 <- select(mriqc2, -c(collection_id:dataset_id))
mriqc2$subjectid <- mriqc2$subjectkey
fsqc <- read.delim(paste0(data_dir,"freesqc01.txt"))
fsqc = fsqc[-1,]
fsqc = droplevels(fsqc)
fsqc <- select(fsqc, -c(collection_id:dataset_id))
fsqc$subjectid <- fsqc$subjectkey
betnet <- read.delim(paste0(data_dir,"abcd_betnet02.txt"))
betnet = betnet[-1,]
betnet = droplevels(betnet)
betnet <- select(betnet, -c(collection_id:dataset_id))
betnet$subjectid <- betnet$subjectkey
sites <- read.delim(paste0(data_dir,"abcd_lt01.txt"))
sites = sites[-1,]
sites = droplevels(sites)
sites <- select(sites, -c(collection_id:dataset_id))
sites$subjectid <- sites$subjectkey
sites <- read.delim(paste0(data_dir,"abcd_lt01.txt"))
sites = sites[-1,]
sites = droplevels(sites)
sites <- select(sites, -c(collection_id:dataset_id))
sites$subjectid <- sites$subjectkey
rawimages= read.delim(paste0(data_dir,"image03.txt"))
rawimages = rawimages[-1,]
rawimages = droplevels(rawimages)
rawimages$subjectid <- rawimages$subjectkey
main<- left_join(procfmri,mriqc1, by="subjectid")
main<- left_join(main,mriqc2, by="subjectid")
main<- left_join(main,fsqc, by="subjectid")
main<- left_join(main,betnet, by="subjectid")
main<- left_join(main,sites, by="subjectid")
main<- left_join(main,rawimages, by="subjectid")
#write.csv(main,paste0(data_dir,"image_and_demo_data_release2_071319.csv"))
```

## Filter by participants who passed FS QC

```{r FS QC filter}
goodFreeSurfer <- main$subjectid[which(main$fsqc_qc == 1)]
goodFreeSurfer <- goodFreeSurfer[!is.na(goodFreeSurfer)]
print(paste("Yay: ", length(goodFreeSurfer), " Nay: ", length(main$subjectid[!is.na(main$fsqc_qc)]) - length(goodFreeSurfer), sep=""))
main<- filter(main, fsqc_qc==1)
```
Pull only participants with good FS, procfmri from 46792 to 46125.

## Filter by participants who have T1's in procfmri
## Find participants with more than 10 min of good resting-state data
```{r With T1s}
subjs <- main$subjectid[which(main$scan_type == "MR structural (T1)")]
length(subjs)
length(unique(subjs))
main <- filter(main, subjectid %in% subjs)
```
30655 subjects (10925 unique subjects) with processed T1s in procfmri. Filtering by these subjects reduces size of procfmri to 322265. 

## Find participants with more than 10 min of good resting-state data and good T1s
```{r Only good data}
#turn from factors into numeric
main$iqc_rsfmri_ok_ser <- as.numeric(as.character(main$iqc_rsfmri_ok_ser))
main$iqc_t1_ok_ser <- as.numeric(as.character(main$iqc_t1_ok_ser))
main$rsfmri_c_ngd_ntpoints<- as.numeric(as.character(main$rsfmri_c_ngd_ntpoints))
main <- filter(main, iqc_rsfmri_ok_ser>=2 &iqc_t1_ok_ser > 0 & rsfmri_c_ngd_ntpoints > 750)
dim(main)
length(unique(main$subjectid))
```
NOTE: Now am pulling every who has 2 or more good quality scans, since motion exclusions resulted in too little data. 10 minutes of quality resting-state fMRI files (i.e., 5 mins x 60 secs x 0.8 TR = 375)
ABCD MRI QC Raw Part 1: iqc_rsfmri_ok_ser > 0 
ABCD MRI QC Raw Part 1: iqc_t1_ok_ser > 0 (for registration to T1w image)
ABCD rsfMRI Gordon Network Correlations: rsfmri_c_ngd_ntpoints > 375 (if use 750, that gives 10 min of data)

Results in 6439 unique participants. Main filtering is on the rsfmri good timepoints.

## Filter out all participants with mean motion above 0.2 mm or 0.3 mm
```{r Filter on motion}
main$iqc_rsfmri_ok_mean_motion_filt<- as.numeric(as.character(main$iqc_rsfmri_ok_mm_filt))

subj_list_0.2mm_FD<- main %>% filter(., iqc_rsfmri_ok_mean_motion_filt< 0.2) %>% select(subjectid,site_id_l, interview_age.x, iqc_rsfmri_ok_mean_motion, iqc_rsfmri_ok_mean_motion_filt, scan_type)
subj_list_0.3mm_FD<- main %>% filter(., iqc_rsfmri_ok_mean_motion_filt< 0.3) %>% select(subjectid, site_id_l, interview_age.x, iqc_rsfmri_ok_mean_motion, iqc_rsfmri_ok_mean_motion_filt)
length(unique(main$subjectid))
length(unique(subj_list_0.2mm_FD$subjectid))
length(unique(subj_list_0.3mm_FD$subjectid))
```
0.2 mm threshold with the respiratory filtering leaves 5270 from 6439 unique subjects.
0.3 mm threshold with the respiratory filtering leaves 6090 from 6439 unique subjects.

## Pick a few sites with more subjects
```{r Look at site distributions}
view(dfSummary(select(main, site_id_l)))
freq(subj_list_0.2mm_FD$site_id_l)
## Filter out participants from only three sites
two_sites_only_s14s20_0.2mm_FD <- filter(subj_list_0.2mm_FD, site_id_l=="site20"|site_id_l=="site14")
two_sites_only_0.3mm_FD <- filter(subj_list_0.3mm_FD, site_id_l=="site20"|site_id_l=="site14")
one_site_only_site16_0.2mm_FD <- filter(subj_list_0.2mm_FD,site_id_l=="site16")
one_site_only_site16_0.3mm_FD <- filter(subj_list_0.3mm_FD,site_id_l=="site16")
```

Site20, Site16, and Site14 have the largest number of images, pick them.
For one site, use Site16, which has 14% of images and n=716.

## Write out subject lists for three sites
```{r Write out subject lists}
length(unique(one_site_only_site16_0.2mm_FD$subjectid))
length(unique(one_site_only_site16_0.3mm_FD$subjectid))
subjlist_2_sites_0.2mm_FD <- unique(two_sites_only_s14s20_0.2mm_FD$subjectid)
subjlist_2_sites_0.3mm_FD <- unique(two_sites_only_0.3mm_FD$subjectid)
subjlist_1_site_0.2mm_FD <- unique(one_site_only_site16_0.2mm_FD$subjectid)
subjlist_1_site_0.3mm_FD <- unique(one_site_only_site16_0.3mm_FD$subjectid)
write.csv(subjlist_2_sites_0.2mm_FD, paste0(subjlist_dir, "n620_release2_site14_site20_0.2mm.csv"))
write.csv(subjlist_2_sites_0.3mm_FD, paste0(subjlist_dir, "n730_release2_site14_site20_0.3mm.csv"))
write.csv(subjlist_1_site_0.2mm_FD, paste0(subjlist_dir, "n716_release2_site16_0.2mm.csv"))
write.csv(subjlist_1_site_0.3mm_FD, paste0(subjlist_dir, "n799_release2_site16_0.3mm.csv"))
```
The two replication sites together have 620 subjects < 0.2 mm FD, 730 subjects < 0.3 mm.
Site16 has 799 participants with 10 min of rest and < 0.3 mm FD (with resp filter) average, 716 < 0.2mm.

## Read them back in and write out AWS addresses for 0.3 mm two sites
```{r Merge in image data, echo=FALSE}
subjlist <- read.csv(paste0(subjlist_dir, "n730_release2_site14_site16_0.3mm.csv"))
subjlist$subjectid <- subjlist$x
image_files <- left_join(subjlist, rawimages, by="subjectid")
image_files <- filter(image_files, visit=="baseline_year_1_arm_1")
image_files_rest_T1s <- filter(image_files, image_description %in% c("ABCD-T1", "ABCD-rsfMRI", "ABCD-T1-NORM", "ABCD-fMRI-FM-PA", "ABCD-fMRI-FM-AP"))
AWS_release2_site14site16_0.3mm_rest_T1s <- select(image_files_rest_T1s, image_file)
write.table(AWS_release2_site14site16_0.3mm_rest_T1s$image_file, paste0(subjlist_dir, "AWS_release2_site14site16_0.3mm_rest_T1s.txt"), row.names = FALSE, quote = FALSE, col.names = FALSE)
```

## Read them back in and write out AWS addresses for 0.2 mm two sites
```{r Merge in image data, echo=FALSE}
subjlist <- read.csv(paste0(subjlist_dir, "n620_release2_site14_site16_0.2mm.csv"))
subjlist$subjectid <- subjlist$x
image_files <- left_join(subjlist, rawimages, by="subjectid")
#filter for only the first visit
image_files <- filter(image_files, visit=="baseline_year_1_arm_1")
image_files_rest_T1s <- filter(image_files, image_description %in% c("ABCD-T1", "ABCD-rsfMRI", "ABCD-T1-NORM", "ABCD-Diffusion-FM-AP","ABCD-Diffusion-FM-PA","ABCD-DTI", "ABCD-fMRI-FM-PA", "ABCD-fMRI-FM-AP"))
AWS_release2_site14site20_rest_T1s_dwis <- select(image_files_rest_T1s, image_file)
write.table(AWS_release2_site14site20_rest_T1s_dwis$image_file, paste0(subjlist_dir, "AWS_release2_site14site16_0.2mm_rest_T1s_dwis.txt"), row.names = FALSE, quote = FALSE, col.names = FALSE)
```

## Read them back in and write out AWS addresses for one site at 0.2 mm
```{r Merge in image data, echo=FALSE}
subjlist <- read.csv(paste0(subjlist_dir, "n716_release2_site20_0.2mm.csv"))
subjlist$subjectid <- subjlist$x
image_files <- left_join(subjlist, rawimages, by="subjectid")
image_files <- filter(image_files, visit=="baseline_year_1_arm_1")
image_files_rest_T1s <- filter(image_files, image_description %in% c("ABCD-T1", "ABCD-rsfMRI", "ABCD-T1-NORM","ABCD-fMRI-FM-PA", "ABCD-fMRI-FM-AP"))
AWS_one_site_0.2mm_rest_T1s <- select(image_files_rest_T1s, image_file)
write.table(AWS_one_site_0.2mm_rest_T1s$image_file, paste0(subjlist_dir, "AWS_release2_site20_0.2mm_rest_T1s.txt"), row.names = FALSE, quote = FALSE, col.names = FALSE)
```

## Read them back in and write out AWS addresses for one site at 0.2 mm with diffusion data
```{r Merge in image data, echo=FALSE}
subjlist <- read.csv(paste0(subjlist_dir, "n716_release2_site20_0.2mm.csv"))
subjlist$subjectid <- subjlist$x
image_files <- left_join(subjlist, rawimages, by="subjectid")
image_files <- filter(image_files, visit=="baseline_year_1_arm_1")
image_files_rest_T1s <- filter(image_files, image_description %in% c("ABCD-T1", "ABCD-rsfMRI", "ABCD-T1-NORM", "ABCD-Diffusion-FM-AP","ABCD-Diffusion-FM-PA","ABCD-DTI", "ABCD-fMRI-FM-PA", "ABCD-fMRI-FM-AP"))
AWS_one_site_0.2mm_rest_T1s <- select(image_files_rest_T1s, image_file)
write.table(AWS_one_site_0.2mm_rest_T1s$image_file, paste0(subjlist_dir, "AWS_release2_site20_0.2mm_rest_T1s_dwis.txt"), row.names = FALSE, quote = FALSE, col.names = FALSE)
```
Adding DWIs for Matt ups the number of tar.gz files for download from 3607 lines to 4381 lines.